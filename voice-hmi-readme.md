# ðŸŽ¤ Voice HMI Module - TTS & STT

## Wprowadzenie

ModuÅ‚ gÅ‚osowy rozszerza uproszczony system HMI o moÅ¼liwoÅ›ci:
- **STT** (Speech-to-Text) - rozpoznawanie komend gÅ‚osowych
- **TTS** (Text-to-Speech) - synteza mowy dla feedbacku
- **Multi-modal** - kombinacja gestÃ³w i gÅ‚osu

## ðŸš€ Szybki Start

### 1. Podstawowa inicjalizacja

```javascript
import { HMIManager } from './simple-hmi-system.js';
import { VoiceHMI } from './voice-hmi-module.js';

// Inicjalizacja
const hmi = new HMIManager({ debug: true });
const voiceHMI = new VoiceHMI(hmi, {
    language: 'pl-PL',
    voiceFeedback: true
});

// Start (wymaga interakcji uÅ¼ytkownika)
button.onclick = () => {
    hmi.start();
    voiceHMI.start();
};
```

### 2. Rejestracja komend gÅ‚osowych

```javascript
// Prosta komenda
voiceHMI.gesture('save_file')
    .voice(/zapisz|save/i)
    .on(() => {
        saveCurrentFile();
    })
    .speak('Zapisano plik');

// Komenda z parametrami
voiceHMI.gesture('go_to_page')
    .voice(/strona (\d+)|page (\d+)/i)
    .on((data) => {
        const pageNum = data.transcript.match(/\d+/)[0];
        navigateToPage(pageNum);
    })
    .speak((data) => `PrzechodzÄ™ do strony ${pageNum}`);
```

### 3. Multi-modal (gÅ‚os + gest)

```javascript
// UsuÅ„ mÃ³wiÄ…c "usuÅ„" i rysujÄ…c okrÄ…g
voiceHMI.multiModalGesture('smart_delete')
    .whenSaying(/usuÅ„|delete/i)
    .whileGesturing('circle', { minRadius: 50 })
    .then(() => {
        deleteSelectedInCircle();
        voiceHMI.tts.speak('UsuniÄ™to elementy');
    });
```

## ðŸ“– API Reference

### VoiceRecognition (STT)

```javascript
const stt = new VoiceRecognition({
    language: 'pl-PL',      // JÄ™zyk rozpoznawania
    continuous: true,       // CiÄ…gÅ‚e nasÅ‚uchiwanie
    interimResults: true,   // Wyniki czÄ™Å›ciowe
    maxAlternatives: 3      // Liczba alternatyw
});

// Metody
stt.start();               // Rozpocznij nasÅ‚uchiwanie
stt.stop();                // Zatrzymaj
stt.registerCommand(pattern, callback); // Rejestruj komendÄ™
stt.setLanguage('en-US');  // ZmieÅ„ jÄ™zyk

// Eventy
stt.on('result', (data) => {
    console.log(data.transcript);    // Rozpoznany tekst
    console.log(data.confidence);    // PewnoÅ›Ä‡ (0-1)
    console.log(data.isFinal);       // Czy finalne
});

stt.on('error', (error) => {
    console.error('STT Error:', error);
});
```

### VoiceSynthesis (TTS)

```javascript
const tts = new VoiceSynthesis({
    language: 'pl-PL',
    rate: 1.0,         // PrÄ™dkoÅ›Ä‡ (0.1-10)
    pitch: 1.0,        // WysokoÅ›Ä‡ (0-2)
    volume: 1.0        // GÅ‚oÅ›noÅ›Ä‡ (0-1)
});

// Metody
await tts.speak('Tekst do przeczytania');
tts.pause();           // Pauza
tts.resume();          // WznÃ³w
tts.stop();            // Zatrzymaj

// Kolejkowanie
tts.speak('Pierwszy tekst', { queue: true });
tts.speak('Drugi tekst', { queue: true });

// RÃ³Å¼ne gÅ‚osy
const voices = tts.getVoices('pl');
tts.setVoice(voices[0]);
```

### VoiceHMI - Integracja

```javascript
// Gesture z gÅ‚osem
voiceHMI.gesture('nazwa')
    .voice(/wzorzec/i)           // Wzorzec regex
    .withGesture('typ', opcje)   // Opcjonalny gest
    .on(callback)                // Handler
    .speak('odpowiedÅº');         // Feedback TTS

// Multi-modal
voiceHMI.multiModalGesture('nazwa')
    .whenSaying(/wzorzec/i)      // Warunek gÅ‚osowy
    .whileGesturing('typ', opcje) // Warunek gestowy
    .then(callback);             // Wykonaj gdy oba speÅ‚nione
```

## ðŸŽ¯ PrzykÅ‚ady UÅ¼ycia

### 1. Nawigacja gÅ‚osowa

```javascript
// Podstawowe komendy
const commands = [
    { pattern: /nastÄ™pny|next/i, action: 'next' },
    { pattern: /poprzedni|back/i, action: 'previous' },
    { pattern: /poczÄ…tek|home/i, action: 'home' },
    { pattern: /koniec|end/i, action: 'end' }
];

commands.forEach(({ pattern, action }) => {
    voiceHMI.gesture(`nav_${action}`)
        .voice(pattern)
        .on(() => navigate(action))
        .speak(`PrzechodzÄ™ ${action}`);
});
```

### 2. Dyktowanie tekstu

```javascript
voiceHMI.gesture('dictation')
    .voice(/napisz (.+)|wpisz (.+)/i)
    .on((data) => {
        const text = data.transcript.replace(/napisz |wpisz /i, '');
        activeInput.value += text;
        voiceHMI.tts.speak(`Wpisano: ${text}`);
    });
```

### 3. Feedback gÅ‚osowy dla akcji

```javascript
class VoiceFeedback {
    constructor(voiceHMI) {
        this.voiceHMI = voiceHMI;
    }

    success(message) {
        this.playSound(800, 0.1); // Wysoki dÅºwiÄ™k
        this.voiceHMI.tts.speak(message, {
            rate: 1.2,
            volume: 0.8
        });
    }

    error(message) {
        this.playSound(200, 0.3); // Niski dÅºwiÄ™k
        this.voiceHMI.tts.speak(`BÅ‚Ä…d: ${message}`, {
            rate: 0.9,
            pitch: 0.8
        });
    }

    playSound(frequency, duration) {
        const context = new AudioContext();
        const oscillator = context.createOscillator();
        oscillator.frequency.value = frequency;
        oscillator.connect(context.destination);
        oscillator.start();
        oscillator.stop(context.currentTime + duration);
    }
}
```

### 4. Accessibility - Screen Reader

```javascript
class ScreenReader {
    constructor(voiceHMI) {
        this.voiceHMI = voiceHMI;
        this.enabled = false;
    }

    enable() {
        this.enabled = true;
        document.addEventListener('focus', this.readElement, true);
        document.addEventListener('mouseover', this.readElement);
        this.voiceHMI.tts.speak('Czytnik ekranu wÅ‚Ä…czony');
    }

    readElement = (event) => {
        if (!this.enabled) return;
        
        const element = event.target;
        const text = this.getAccessibleText(element);
        
        if (text) {
            this.voiceHMI.tts.speak(text, {
                rate: 1.3,
                volume: 0.7
            });
        }
    }

    getAccessibleText(element) {
        return element.getAttribute('aria-label') ||
               element.getAttribute('title') ||
               element.textContent?.trim().substring(0, 100);
    }
}
```

## ðŸŒ ObsÅ‚uga jÄ™zykÃ³w

```javascript
// Zmiana jÄ™zyka w runtime
voiceHMI.stt.setLanguage('en-US');
voiceHMI.tts.options.language = 'en-US';

// Multi-jÄ™zyk
const languages = {
    pl: {
        commands: {
            save: /zapisz|zachowaj/i,
            delete: /usuÅ„|skasuj/i
        },
        responses: {
            saved: 'Zapisano',
            deleted: 'UsuniÄ™to'
        }
    },
    en: {
        commands: {
            save: /save|store/i,
            delete: /delete|remove/i
        },
        responses: {
            saved: 'Saved',
            deleted: 'Deleted'
        }
    }
};

function setupLanguage(lang) {
    const config = languages[lang];
    
    voiceHMI.gesture('save')
        .voice(config.commands.save)
        .on(() => save())
        .speak(config.responses.saved);
}
```

## ðŸ”§ Konfiguracja i optymalizacja

### Redukcja szumÃ³w

```javascript
const stt = new VoiceRecognition({
    // Filtruj krÃ³tkie wypowiedzi
    minTranscriptLength: 3,
    
    // Ignoruj niskÄ… pewnoÅ›Ä‡
    minConfidence: 0.5,
    
    // Timeout ciszy
    silenceTimeout: 3000
});

stt.on('result', (data) => {
    if (data.confidence < 0.5) return; // Ignoruj
    if (data.transcript.length < 3) return; // Za krÃ³tkie
    
    processCommand(data);
});
```

### Optymalizacja TTS

```javascript
// Cache czÄ™sto uÅ¼ywanych fraz
const phraseCache = new Map();

async function speakCached(text, options) {
    if (!phraseCache.has(text)) {
        const audio = await textToAudioBuffer(text, options);
        phraseCache.set(text, audio);
    }
    
    playAudioBuffer(phraseCache.get(text));
}

// Batch TTS dla dÅ‚ugich tekstÃ³w
function speakLongText(text) {
    const sentences = text.split(/[.!?]+/);
    sentences.forEach((sentence, i) => {
        voiceHMI.tts.speak(sentence, {
            queue: true,
            delay: i * 100
        });
    });
}
```

## ðŸ› RozwiÄ…zywanie problemÃ³w

### Brak mikrofonu

```javascript
navigator.mediaDevices.getUserMedia({ audio: true })
    .then(() => {
        console.log('âœ… Mikrofon dostÄ™pny');
        voiceHMI.start();
    })
    .catch((error) => {
        console.error('âŒ Brak dostÄ™pu do mikrofonu:', error);
        showMicrophoneError();
    });
```

### ObsÅ‚uga bÅ‚Ä™dÃ³w STT

```javascript
stt.on('error', (error) => {
    switch(error) {
        case 'no-speech':
            console.log('Nie wykryto mowy');
            break;
        case 'audio-capture':
            console.log('Problem z mikrofonem');
            break;
        case 'not-allowed':
            console.log('Brak uprawnieÅ„');
            requestMicrophonePermission();
            break;
    }
});
```

### Debug mode

```javascript
// WÅ‚Ä…cz szczegÃ³Å‚owe logi
voiceHMI.debug = true;

// Wizualizacja audio
function visualizeAudio() {
    const analyser = audioContext.createAnalyser();
    microphone.connect(analyser);
    
    const canvas = document.getElementById('audio-viz');
    const canvasCtx = canvas.getContext('2d');
    
    function draw() {
        const data = new Uint8Array(analyser.frequencyBinCount);
        analyser.getByteFrequencyData(data);
        
        // Rysuj spektrum
        canvasCtx.clearRect(0, 0, canvas.width, canvas.height);
        data.forEach((value, i) => {
            const height = value / 2;
            canvasCtx.fillRect(i * 2, canvas.height - height, 2, height);
        });
        
        requestAnimationFrame(draw);
    }
    draw();
}
```

## ðŸ“Š Metryki i analityka

```javascript
class VoiceAnalytics {
    constructor() {
        this.metrics = {
            totalCommands: 0,
            recognitionSuccess: 0,
            averageConfidence: 0,
            commandUsage: new Map()
        };
    }

    trackCommand(command, confidence) {
        this.metrics.totalCommands++;
        this.metrics.averageConfidence = 
            (this.metrics.averageConfidence * (this.metrics.totalCommands - 1) + confidence) / 
            this.metrics.totalCommands;
        
        const usage = this.metrics.commandUsage.get(command) || 0;
        this.metrics.commandUsage.set(command, usage + 1);
    }

    getReport() {
        return {
            ...this.metrics,
            successRate: this.metrics.recognitionSuccess / this.metrics.totalCommands,
            topCommands: Array.from(this.metrics.commandUsage.entries())
                .sort((a, b) => b[1] - a[1])
                .slice(0, 5)
        };
    }
}
```

## âœ… Najlepsze praktyki

1. **Zawsze testuj wsparcie przeglÄ…darki**
2. **UÅ¼ywaj visual feedback wraz z audio**
3. **Implementuj fallback dla gestÃ³w**
4. **Cache czÄ™sto uÅ¼ywane frazy TTS**
5. **Ogranicz continuous listening dla baterii**
6. **UÅ¼ywaj odpowiednich jÄ™zykÃ³w i gÅ‚osÃ³w**
7. **Testuj w rÃ³Å¼nych Å›rodowiskach audio**

## ðŸ”— Zasoby

- [Web Speech API - MDN](https://developer.mozilla.org/en-US/docs/Web/API/Web_Speech_API)
- [Speech Recognition Grammar](https://www.w3.org/TR/speech-grammar/)
- [WCAG Speech Guidelines](https://www.w3.org/WAI/WCAG21/Understanding/speech-input)

---

**Voice HMI Module - Making interfaces speak and listen! ðŸŽ¤ðŸ”Š**